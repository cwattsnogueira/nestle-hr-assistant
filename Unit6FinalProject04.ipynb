{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cwattsnogueira/nestle-hr-assistant/blob/main/Unit6FinalProject04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du37j76JxP-p"
      },
      "source": [
        "# Essentials and Applications of Generative AI: Course End Projects\n",
        "\n",
        "Carllos Watts-Nogueira\n",
        "\n",
        "Due:\n",
        "\n",
        "Crafting an AI-Powered HR Assistant: A Use Case for Nestle’s HR Policy Documents\n",
        "\n",
        "**Overview**\n",
        "\n",
        "The project aims to create a conversational chatbot that responds to user inquiries using PDF document information. It requires proficiency in extracting and converting text into numerical vectors, establishing an answer-finding mechanism, and designing a user-friendly chatbot interface with Gradio. Additionally, the initiative emphasizes structuring inquiries for clear communication and deploying the chatbot for practical use, guaranteeing the system's accessibility and efficiency in meeting user needs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmAKVjFsxmVx"
      },
      "source": [
        "# 4) AI-Powered HR Assistant\n",
        "\n",
        "* model_id = \"google/flan-t5-base\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNHUHzMJxlnG",
        "outputId": "ff6870db-3db6-4bab-cb55-5eb1d3f56cfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2 sentence-transformers faiss-cpu transformers gradio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEiNhamkxpjc"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "hf_token = userdata.get(\"hf_token_key\")  # optional for public models\n",
        "os.environ[\"HF_TOKEN\"] = hf_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePnckbciyGD0"
      },
      "outputs": [],
      "source": [
        "!pip install PyPDF2 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxSTYpPFxq4o"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "reader = PdfReader(\"/content/the_nestle_hr_policy_pdf_2012.pdf\")\n",
        "raw_text = \"\\n\".join([page.extract_text() for page in reader.pages])\n",
        "clean_text = \"\\n\".join([line for line in raw_text.split(\"\\n\") if len(line.strip()) > 50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoIxiv-HxvnH"
      },
      "outputs": [],
      "source": [
        "def chunk_text(text, chunk_size=500, overlap=50):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        chunk = text[start:end]\n",
        "        if len(chunk.strip()) > 100:\n",
        "            chunks.append(chunk)\n",
        "        start = end - overlap\n",
        "    return chunks\n",
        "\n",
        "chunks = chunk_text(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473,
          "referenced_widgets": [
            "6a603c90df9547f28e26393a7b893e22",
            "129f7f7a0f7b4966bdd29c0739a6b420",
            "d165b08349864e9f8acd8934a98e4055",
            "a4a0c0fb2410465c98edfcd4faf494a1",
            "3921b8387bb944c287be3f6e25010eea",
            "2dde366087154202be86fed3b52d58a9",
            "8a1239027617430badf0229363385400",
            "df054afa95c2417caab988437fb912f9",
            "ba6f378f792d4801a1906a6188eab4a8",
            "820d2cd4bfe441cb81084c7ffaa333dd",
            "c31adcdadb184b339a4f463dc2a18ae1",
            "55c8115222c9497a8e84bfe3d3c1fac7",
            "164c741662f54288b89f19b9c9783772",
            "e71e4461c8c547baa03009f9d0e78a2b",
            "6c6fe2d6c2104412abd6fcd8cb655959",
            "38d95ece0e084c65a6840988cd551715",
            "f3707ae905e24301b5d96e578c238490",
            "db90037481ea44a183897768a7b665f2",
            "6643e89f5ac544b8818cdc02b91edd6a",
            "be48f649e0f84c25a1b64d5f2f3f7b00",
            "cd37e281a7344caf9e2ddc82027eadbd",
            "1f401d0680644805a42e1724b15b9c5d",
            "e560566be91d49b5a6f4fff93cc9c4b8",
            "6b99d50115494653b987028f115f923c",
            "615879cd96b44c7f88ae1188accccd4d",
            "1c00eec70ae0416c910b4cfd6f88bd57",
            "fb5ca7ef554346808651a7ae66f80347",
            "d7293871cf114755b78922764b217af8",
            "46a8bb0b6ab049d3a14ccd45c79b1f12",
            "81a79e0246cd4f7f9550632a3e40a48c",
            "5608ceea28544d4bb7de25c362e85fd3",
            "30884af686c94da2917a39da9dbe95b7",
            "d78e00f06c1d45379378dd6ee4b0df9a",
            "88b6ebb73c8740a3954a867962cd332f",
            "fa10d23ba5db47db8a1da18765de2d19",
            "9803b732c3d742bdb08356e3d8fe47f7",
            "98910de73e46407d8da676e337fd2091",
            "4dad7616ae704eea81d057912a9c161a",
            "b852ddee09994d43b20bb9ac2028ceb7",
            "935d62f093ac49fcb07014cdfcbbcdec",
            "27f71735e2984743a79e4cba33607ab1",
            "22bafbc2627446749effb7d0f825d031",
            "74ce6d9299d34030a7997e321e6325a8",
            "159e2918338449be928813cd2599874c",
            "09763757425548fdb5faa9ed36591f22",
            "de9c9d6aeeec445e9f1641a2b263e6ce",
            "50f50adee62745a0a2d7f73773d1fecb",
            "0a73aeb81801413782d1b3490cd706b7",
            "958a170dc0224efb81588a2c16abc281",
            "3913f5cc1eba419a92ad814c8c6f1699",
            "c57def4e591443d6a9dfa47aea7791b4",
            "3908f5d73ed64bc78af7b3f3bf03540d",
            "df0fe11697294f14b29d0cfdf7589eee",
            "823967629744408db6df3743769ced06",
            "06af92a650dc4225a790b0da6e32c633",
            "3c490c279e724f129f276e04a2ccb5e6",
            "2ba7a0f98de74898a416d0d523f6373a",
            "4c06763ab4c845db82dadddcf02b4456",
            "94ca4111364f4e61959e23f98d193d31",
            "2538f6d1bc194b98a7e1070ae85c0d31",
            "915060b7ca6b47c9a3465aa7342e37da",
            "d4b0165446664ba7bceb0d82d4043f3b",
            "7eecdb2bc20240fea1b145ed67720965",
            "1d77a79f79094137bea4974000270a84",
            "3fee4bfb43b84db18f24e6671c1f897e",
            "bdb98355cb4047c9b7a6b8180ba774dc",
            "ac39c78ba80b4ffa8d538952ce9c1198",
            "566cd588889046e19e4b6779646734de",
            "c3407cf5679649a98307a6249ca4d0c4",
            "9368f1858afb4afda02333083ab0a23f",
            "7b51493e6e5947e3a17682c500f1a8bb",
            "ac46a4b9f05d4760afe650ed8e0ca017",
            "556b815bc51d48458efc76b50da16645",
            "555b6505f2e2490e837a31e62fb5dd25",
            "9de35e99e89646fd96527814017b468a",
            "64fe02cf61bb49c9874f40e6cfeab9e6",
            "9a004abca8b342b6bd7b20ecfedc1d77",
            "8dc61e43f78d4ef1aa14f5d613ad0e8a",
            "b38f570f6bb644398235a2e5e93dfae9",
            "0544ef1252244e6fa6a41b1cd8cb1fb8",
            "bc0271f180ee483987d2c74a0fb08f47",
            "d27531565d1248e69fd754ae8ebd6be3",
            "bf365c56c18e49f3ad4de62ce636ab99",
            "a6ebc12329ec451a84afd7d07bdeba0f",
            "5118961257594ea085ca67b6ed2acbe4",
            "7469e409fe7142f39446c9573815c176",
            "73038a4550744e47bb87fae7d29489b5",
            "e5feae77d2474e8bbf45202b1ba842e0",
            "a5f8008cda3540e283493f01f3c8274a",
            "e64187bed5ae445a958b28db3db103b5",
            "aa4a832ade4041c7b93b0da2e15cc0ed",
            "b7cdd0975e3645a5b59341ae3ed7f6ae",
            "01f0636819f148b0b98c724575b63f2c",
            "eac34dd730374cf3964d308813bf80bb",
            "bc924039ed144482a1edec3f313db9d9",
            "37b0272e0a24471ca4099a8fb8542a69",
            "ed793d9fb7da4de4be0a2cbf520bbcab",
            "0ac04b0e4fb645fca8c5277d38285252",
            "cb3a30f6ce8744eab6b6411c86ede593",
            "b3756d2cedb24857b775fddcc07aca6e",
            "cec2dd63a4a24afbb8f10bd37d7bd3c7",
            "70a23f0a220f4a84880976fbf105c07d",
            "57ad7c03684c4f61870fc88a7a647d54",
            "9dddfd8ce3f14f3baa1449182145eadf",
            "4833106f1e5949cfab8d476f99018858",
            "03972f632ffe46509a399a378e83958c",
            "bfc42b8a55fd4e0698236a8cc659f6d9",
            "82c32a04966346b59fe45bb93530cb62",
            "bddba2ea2a0543bf9e44ba9002980bf8",
            "6b149de4147149deac371383bcaf5662",
            "4d4ed7135310410c8f23825765e7324a",
            "24a2c93dca314d0691aac9fbda8d7572",
            "7d50dbfe3ced4d7fb413a22befe42865",
            "5be7ad8712f2448fabf2f4f8bf605933",
            "3a7ff83060b24f038abd3d61804bca5b",
            "a295229dc9514c09b9e346bfe9286838",
            "fb2aaa0b32284ce1aec42327cfbbd59a",
            "c89493620ef9402dba5ea8b16f3d8565",
            "96a9ee1006b34a199706fcfd2ff0e7b4",
            "2ae40b02505144e08bd61097ffc00db4",
            "61d597c3f03742d690da1ad2a55806e2"
          ]
        },
        "id": "00ff8YBBxxZq",
        "outputId": "8a3cab30-fe84-46d0-ec7f-742fddb1eac5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a603c90df9547f28e26393a7b893e22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55c8115222c9497a8e84bfe3d3c1fac7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e560566be91d49b5a6f4fff93cc9c4b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88b6ebb73c8740a3954a867962cd332f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09763757425548fdb5faa9ed36591f22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c490c279e724f129f276e04a2ccb5e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac39c78ba80b4ffa8d538952ce9c1198",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dc61e43f78d4ef1aa14f5d613ad0e8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5f8008cda3540e283493f01f3c8274a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3756d2cedb24857b775fddcc07aca6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d4ed7135310410c8f23825765e7324a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = embed_model.encode(chunks)\n",
        "\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(np.array(embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "d7010bbc7af1413aa2a209bb29ae19f5",
            "85d0ad1b6d1a48749fe330f1fd100c01",
            "ec941a4f815346208ca988acb7de2578",
            "33b1fcd0c28d4039b19a26e4c0d27282",
            "896aee1932294441983082d8573c155a",
            "7a8dafaa7ef941b4832e5eb49cb1d6c1",
            "32f20d319109472a9802b9cf52be341d",
            "a1ce64d072464fc9b3a099c214253854",
            "d4a0c39f92e7408aa50f611154cc1726",
            "32947b00cb5d421a835fa5f5fe36fcbb",
            "990bbf178d644969be3d18711518f9b2",
            "0a0eba8f681b4872bc0da125569e5ab6",
            "38fbdbd7af8e4d24b9f5532975cbfa81",
            "90b67ac367dd4c8f85f717adf980d585",
            "b9dd97bae7934744a20185a3dfb92b7e",
            "b09a0ba3f09d4258884fb5e0b1dd14e1",
            "2972315711304cc29388742e572ec1a0",
            "84400bbec7e44040b18c872ce7b43606",
            "fa3c33fac5cf493dbe3dbd09ff2dcd8e",
            "ad7da7095c904c03b25a43b47725c0b5",
            "9ebedf0912484205824d2ab0b6321499",
            "a54c1970bfb64118848d7b1573503249",
            "4f1bd7a3e8ca4aea87143eaf500a65cf",
            "3fcce1a605bb4215971ade766a97f730",
            "f384142b9bf54be489a9afa118e37c3a",
            "b5767d2258b44f8a84da13727412287c",
            "0d72b62ecbeb491aadf5dd226242182a",
            "014043593ae14cf59a77115fa22b6b6e",
            "e79bb8663e144b57a18c6b898b8c40f1",
            "f2f421254cf445de91e1624339b487c5",
            "d20345484e6b4ccc96f27df43c6626ed",
            "16276c60f8f54b42b8f0d744324e84f9",
            "0b2da8d6e0a84e69a4fb5089ccc8bff5",
            "f9a8d9d0c3c54094b979d20416e71863",
            "cd6aa7c96f514978a17b998e17df0a21",
            "ada352e05e3e491c8c11348044226bab",
            "da59ad1ce1484f6da53fdf0f212918c2",
            "936b005d2666453c93a341ca8575f666",
            "4c57b9cd1efb4c8e9ab34a3b70a9b6c9",
            "3321d518e3fb49f7bd761324dd494252",
            "aecf82aec96345a693bb599993de30a8",
            "ae3d78c101a04e1b94ae5fc61c2c3a12",
            "e0d73013285c44b4a59a78f600429d70",
            "b24b3e7892d942dc8271ba6ca52a92bf",
            "b3220315cab64ea2b0c291abb6e4d40e",
            "817288c30af64983a77dcaf69dbf6b43",
            "7086cf0ee97247d59faf950aa152106b",
            "5d8888c7d4be4a1b903be6333c3f3fd8",
            "e3eb24a7f8074325b8facc2cc7096459",
            "3d657b947734411b96ac82cd926dc07b",
            "8beaf40a9c6f4c9c8f0af750c2900b64",
            "e4cb2fc2d0224b3a8f848d5c92fb51ca",
            "26358579329645e8857f1cf323820992",
            "00212cd8a656451f9675b6d7aeafa9a1",
            "652b4fe4bf724493b20e844a9145ad36",
            "ac838b8595114045800f92f76569bb9d",
            "f0d61be21a0a49cc89266c87b2f0da9c",
            "35a1d103a0d04976945db7028d6467b4",
            "086fd2f4782843158d711ca941a4924e",
            "db2c21627c34447e9634ad9c3536ebb1",
            "4883d67cf0304cb697f0658dcd1e1c75",
            "8e769bd5afd740fe8a8170b1719c9fea",
            "df93eb607aa345ba8a6ddf2137ecdc55",
            "8db93da5d6d146dfa17d3ebe4f0b346d",
            "1aba2d73123540be8f73717e8f94e31a",
            "d2974fdb7eb6415da9a6f3c50e324f84",
            "a70cc3f15ca64ff39bdbd652c0b9df36",
            "eb8b6c4379af4f718572227844efc15b",
            "20164adf331c48938535955840ff56c3",
            "8266535a2fb44d60b5bcaf8773634ea9",
            "0d136cfc190f4f4b92811ad6e31a9d39",
            "891d4fb99e1f43d18edc9c7fd72db2ac",
            "3d374001ea8f4b57aa8fdb2e496e6e62",
            "f3b6337fc9624af192c2d9b259a42f3d",
            "e4e8c49235084a478b0d6f7ab4f52607",
            "1e2f772e4ec44e5fbcc2f33a23be55e0",
            "506b5e2349cb4618bbec39cf9a313436"
          ]
        },
        "id": "1HdpGjD8x0KX",
        "outputId": "b4553524-ee15-4330-f148-bd5e3e2ad219"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7010bbc7af1413aa2a209bb29ae19f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a0eba8f681b4872bc0da125569e5ab6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f1bd7a3e8ca4aea87143eaf500a65cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9a8d9d0c3c54094b979d20416e71863",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3220315cab64ea2b0c291abb6e4d40e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac838b8595114045800f92f76569bb9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a70cc3f15ca64ff39bdbd652c0b9df36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_id = \"google/flan-t5-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Uo6TbXsx1BX"
      },
      "outputs": [],
      "source": [
        "fallback_text = \"\"\"\n",
        "Nestlé’s Maternity Protection Policy promotes five pillars:\n",
        "1. Employment protection and non-discrimination\n",
        "2. Healthy work environment\n",
        "3. Flexible work arrangements\n",
        "4. Support for breastfeeding\n",
        "5. Gender balance and family-friendly culture\n",
        "\n",
        "The policy aligns with ILO Convention C183 and WHO guidelines on exclusive breastfeeding for the first six months.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ2yvb7nx3JN"
      },
      "outputs": [],
      "source": [
        "def answer_with_flan(query, k=5):\n",
        "    try:\n",
        "        query_embedding = embed_model.encode([query])\n",
        "        distances, indices = index.search(np.array(query_embedding), k)\n",
        "        results = [chunks[i] for i in indices[0] if len(chunks[i].strip()) > 100]\n",
        "\n",
        "        context = \"\\n\\n\".join(results)\n",
        "        context = context[:1000] if context else fallback_text[:1000]\n",
        "\n",
        "        prompt = f\"\"\"You are an HR assistant for Nestlé. Based on the following policy excerpt, answer the user's question.\n",
        "\n",
        "Excerpt:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\"\"\"\n",
        "\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "        output = model.generate(**inputs, max_new_tokens=150)\n",
        "        return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        return f\"Internal error: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "-JM_k2wKx6yn",
        "outputId": "ae3356ed-73d3-4c04-bab2-57484aa291e8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://22960a869927737578.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://22960a869927737578.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "gr.Interface(\n",
        "    fn=answer_with_flan,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Nestlé HR Assistant (Flan-T5)\",\n",
        "    description=\"Ask any HR-related question. This assistant uses Flan-T5 and Nestlé's HR policy.\"\n",
        ").launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXt1o2kgJOsg"
      },
      "source": [
        "# Final Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXsOKNkIJxLn"
      },
      "source": [
        "## Project Overview\n",
        "\n",
        "This project was part of my AI/ML engineering bootcamp, where I built a document-aware HR assistant using Hugging Face models, FAISS retrieval, and Gradio for deployment. The assistant answers HR-related questions based on Nestlé’s internal policy documents, with a fallback mechanism for verified summaries. My goal was to create a modular, memory-safe pipeline that could run reliably in Google Colab.\n",
        "\n",
        "---\n",
        "\n",
        "##  What I Built\n",
        "\n",
        "- **Document ingestion**: I parsed and cleaned a real Nestlé HR policy PDF using `PyPDF2`, removing noise and extracting meaningful text.\n",
        "- **Chunking logic**: I implemented a sliding window chunking strategy to break the document into overlapping segments for better semantic retrieval.\n",
        "- **Embedding and indexing**: I used `sentence-transformers` (MiniLM) to embed the chunks and built a FAISS index for fast similarity search.\n",
        "- **Model selection**: After testing Phi-2 and running into memory and generation issues, I pivoted to `google/flan-t5-base`, which is instruction-tuned and lightweight enough for Colab.\n",
        "- **Prompt engineering**: I crafted clear, role-based prompts to guide the model’s behavior as an HR assistant, including fallback summaries when retrieval failed.\n",
        "- **Gradio interface**: I deployed the assistant with a clean UI, allowing users to ask questions and receive answers in real time.\n",
        "\n",
        "---\n",
        "\n",
        "##  What I Learned\n",
        "\n",
        "###  Technical Skills\n",
        "\n",
        "- How to securely authenticate with Hugging Face using Colab secrets and environment variables.\n",
        "- How to handle large models in constrained environments using `low_cpu_mem_usage`, prompt trimming, and token limits.\n",
        "- How to build a retrieval-augmented generation (RAG) pipeline using FAISS and sentence embeddings.\n",
        "- How to debug model loading errors, memory crashes, and generation stalls — and how to pivot to better-suited architectures.\n",
        "- How to wrap generation in timeout-safe logic using `concurrent.futures` to prevent Gradio from hanging.\n",
        "\n",
        "###  Design Principles\n",
        "\n",
        "- The importance of fallback logic when retrieval fails or returns irrelevant chunks.\n",
        "- How prompt clarity and structure directly affect model output quality.\n",
        "- Why model selection matters — not just for performance, but for reliability and user experience.\n",
        "- How to modularize code for reusability, debugging, and future scaling.\n",
        "\n",
        "---\n",
        "\n",
        "##  Challenges I Faced\n",
        "\n",
        "- Phi-2 repeatedly stalled during generation in Colab, even with trimmed prompts and fallback logic.\n",
        "- FAISS sometimes retrieved irrelevant chunks, which required manual filtering and fallback summaries.\n",
        "- Gradio would hang if the model didn’t respond quickly, so I had to implement timeout protection.\n",
        "\n",
        "---\n",
        "\n",
        "##  Final Outcome\n",
        "\n",
        "The final assistant runs smoothly in Colab, responds quickly to HR-related questions, and uses verified fallback content when needed. It’s modular, reproducible, and ready for deployment or extension. I now understand how to build document-aware assistants from scratch, and how to adapt when models or environments don’t behave as expected."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}